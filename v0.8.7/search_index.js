var documenterSearchIndex = {"docs":
[{"location":"api/#Exported-functions-and-types-1","page":"API","title":"Exported functions and types","text":"","category":"section"},{"location":"api/#Index-1","page":"API","title":"Index","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"","category":"page"},{"location":"api/#","page":"API","title":"API","text":"Modules = [MonteCarloMeasurements]\nPrivate = false","category":"page"},{"location":"api/#MonteCarloMeasurements.Particles","page":"API","title":"MonteCarloMeasurements.Particles","text":"struct Particles{T, N} <: AbstractParticles{T, N}\n\nThis type represents uncertainty using a cloud of particles.\n\nConstructors:\n\nParticles()\nParticles(N::Integer)\nParticles([rng::AbstractRNG,] d::Distribution)\nParticles([rng::AbstractRNG,] N::Integer, d::Distribution; permute=true, systematic=true)\nParticles(v::Vector{T} where T)\nParticles(m::Matrix{T} where T): Creates multivariate particles (Vector{Particles})\n\n\n\n\n\n","category":"type"},{"location":"api/#MonteCarloMeasurements.StaticParticles","page":"API","title":"MonteCarloMeasurements.StaticParticles","text":"struct StaticParticles{T, N} <: AbstractParticles{T, N}\n\nSee ?Particles for help. The difference between StaticParticles and Particles is that the StaticParticles store particles in a static vecetor. This makes runtimes much shorter, but compile times longer. See the documentation for some benchmarks. Only recommended for sample sizes of ≲ 300-400\n\n\n\n\n\n","category":"type"},{"location":"api/#MonteCarloMeasurements.Workspace","page":"API","title":"MonteCarloMeasurements.Workspace","text":"struct Workspace{T1, T2, T3, T4, T5, T6}\n\nDOCSTRING\n\n#Arguments:\n\nsimple_input: Input object f will be called with, does not contain any particles\nsimple_result: Simple output from f without particles\nresult: Complete output of f including particles\nbuffersetter: Helper function to shift data between objects\nresultsetter: Helper function to shift data between objects\nf: Function to call\nN: Number of particles\n\n\n\n\n\n","category":"type"},{"location":"api/#MonteCarloMeasurements.Workspace-Tuple{Any,Any}","page":"API","title":"MonteCarloMeasurements.Workspace","text":"Workspace(f, input)\n\nCreate a Workspace object for inputs of type typeof(input). Useful if input is a structure with fields of type <: AbstractParticles (can be deeply nested). See also with_workspace.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.:..-Tuple{Any,Any}","page":"API","title":"MonteCarloMeasurements.:..","text":"a .. b\n\nCreates 10000 Particles with a Uniform distribution between a and b. See also ±, ⊗\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.:±","page":"API","title":"MonteCarloMeasurements.:±","text":"μ ± σ\n\nCreates 10000 Particles with mean μ and std σ. If μ is a vector, the constructor MvNormal is used, and σ is thus treated as std if it's a scalar, and variances if it's a matrix or vector. See also ∓, ..\n\n\n\n\n\n","category":"function"},{"location":"api/#MonteCarloMeasurements.:∓","page":"API","title":"MonteCarloMeasurements.:∓","text":"μ ∓ σ\n\nCreates 100 StaticParticles with mean μ and std σ. If μ is a vector, the constructor MvNormal is used, and σ is thus treated as std if it's a scalar, and variances if it's a matrix or vector. See also ±, ⊗\n\n\n\n\n\n","category":"function"},{"location":"api/#MonteCarloMeasurements.bootstrap-Union{Tuple{T}, Tuple{AbstractRNG,T}} where T<:AbstractParticles","page":"API","title":"MonteCarloMeasurements.bootstrap","text":"bootstrap([rng::AbstractRNG,] p::Particles)\n\nReturn Particles resampled with replacement.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.bymap-Union{Tuple{F}, Tuple{F,Vararg{Any,N} where N}} where F","page":"API","title":"MonteCarloMeasurements.bymap","text":"bymap(f, args...)\n\nCall f with particles or vectors of particles by using map. This can be utilized if registering f using register_primitive fails. See also Workspace if bymap fails.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.errorbarplot","page":"API","title":"MonteCarloMeasurements.errorbarplot","text":"errorbarplot(x,y,[q=0.025])\n\nPlots a vector of particles with error bars at quantile q. If q::Tuple, then you can specify both lower and upper quantile, e.g., (0.01, 0.99).\n\n\n\n\n\n","category":"function"},{"location":"api/#MonteCarloMeasurements.ess-Tuple{AbstractParticles}","page":"API","title":"MonteCarloMeasurements.ess","text":"ess(p::AbstractParticles{T,N})\n\nCalculates the effective sample size. This is useful if particles come from MCMC sampling and are correlated in time. The ESS is a number between [0,N].\n\nInitial source: https://github.com/tpapp/MCMCDiagnostics.jl\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.has_particles-Tuple{Any}","page":"API","title":"MonteCarloMeasurements.has_particles","text":"has_particles(P)\n\nDetermine whether or no the object P has some kind of particles inside it. This function examins fields of P recursively and looks inside arrays etc.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.mcplot","page":"API","title":"MonteCarloMeasurements.mcplot","text":"mcplot(x,y,[q=0.025])\n\nPlots all trajectories represented by a vector of particles\n\n\n\n\n\n","category":"function"},{"location":"api/#MonteCarloMeasurements.mean_object-Tuple{AbstractParticles}","page":"API","title":"MonteCarloMeasurements.mean_object","text":"mean_object(x)\n\nReturns an object similar to x, but where all internal instances of Particles are replaced with their mean. The generalization of this function is replace_particles.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.outer_product","page":"API","title":"MonteCarloMeasurements.outer_product","text":"p = outer_product([rng::AbstractRNG,] dists::Vector{<:Distribution}, N=100_000)\n\nCreates a multivariate systematic sample where each dimension is sampled according to the corresponding univariate distribution in dists. Returns p::Vector{Particles} where each Particles has a length approximately equal to N. The particles form the outer product between d systematically sampled vectors with length given by the d:th root of N, where d is the length of dists, All particles will be independent and have marginal distributions given by dists.\n\nSee also MonteCarloMeasurements.⊗\n\n\n\n\n\n","category":"function"},{"location":"api/#MonteCarloMeasurements.register_primitive","page":"API","title":"MonteCarloMeasurements.register_primitive","text":"register_primitive(f, eval=eval)\n\nRegister both single and multi-argument function so that it works with particles. If you want to register functions from within a module, you must pass the modules eval function.\n\n\n\n\n\n","category":"function"},{"location":"api/#MonteCarloMeasurements.register_primitive_multi","page":"API","title":"MonteCarloMeasurements.register_primitive_multi","text":"register_primitive_multi(ff, eval=eval)\n\nRegister a multi-argument function so that it works with particles. If you want to register functions from within a module, you must pass the modules eval function.\n\n\n\n\n\n","category":"function"},{"location":"api/#MonteCarloMeasurements.register_primitive_single","page":"API","title":"MonteCarloMeasurements.register_primitive_single","text":"register_primitive_single(ff, eval=eval)\n\nRegister a single-argument function so that it works with particles. If you want to register functions from within a module, you must pass the modules eval function.\n\n\n\n\n\n","category":"function"},{"location":"api/#MonteCarloMeasurements.ribbonplot","page":"API","title":"MonteCarloMeasurements.ribbonplot","text":"ribbonplot(x,y,[q=0.025])\n\nPlots a vector of particles with a ribbon covering quantiles q, 1-q. If q::Tuple, then you can specify both lower and upper quantile, e.g., (0.01, 0.99).\n\n\n\n\n\n","category":"function"},{"location":"api/#MonteCarloMeasurements.set_comparison_function-Tuple{Any}","page":"API","title":"MonteCarloMeasurements.set_comparison_function","text":"set_comparison_function(f)\n\nChange the Function used to reduce particles to a number for comparison operators Toggle the use of a comparison Function without warning using the Function unsafe_comparisons.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.sigmapoints-Tuple{Any,AbstractArray{T,2} where T}","page":"API","title":"MonteCarloMeasurements.sigmapoints","text":"sigmapoints(m, Σ)\nsigmapoints(d::Normal)\nsigmapoints(d::MvNormal)\n\nThe unscented transform uses a small number of points to propagate the first and second moments of a probability density, called sigma points. We provide a function sigmapoints(μ, Σ) that creates a Matrix of 2n+1 sigma points, where n is the dimension. This can be used to initialize any kind of AbstractParticles, e.g.:\n\njulia> m = [1,2]\n\njulia> Σ = [3. 1; 1 4]\n\njulia> p = StaticParticles(sigmapoints(m,Σ))\n2-element Array{StaticParticles{Float64,5},1}:\n (5 StaticParticles: 1.0 ± 1.73)\n (5 StaticParticles: 2.0 ± 2.0)\n\njulia> cov(p) ≈ Σ\ntrue\n\njulia> mean(p) ≈ m\ntrue\n\nMake sure to pass the variance (not std) as second argument in case μ and Σ are scalars.\n\nCaveat\n\nIf you are creating several one-dimensional uncertain values using sigmapoints independently, they will be strongly correlated. Use the multidimensional constructor! Example:\n\np = StaticParticles(sigmapoints(1, 0.1^2))               # Wrong!\nζ = StaticParticles(sigmapoints(0.3, 0.1^2))             # Wrong!\nω = StaticParticles(sigmapoints(1, 0.1^2))               # Wrong!\n\np,ζ,ω = StaticParticles(sigmapoints([1, 0.3, 1], 0.1^2)) # Correct\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.systematic_sample","page":"API","title":"MonteCarloMeasurements.systematic_sample","text":"systematic_sample([rng::AbstractRNG,] N, d=Normal(0,1); permute=true)\n\nreturns a Vector of length N sampled systematically from the distribution d. If permute=false, this vector will be sorted.\n\n\n\n\n\n","category":"function"},{"location":"api/#MonteCarloMeasurements.transform_moments-Tuple{Any,Any,Any}","page":"API","title":"MonteCarloMeasurements.transform_moments","text":"Y = transform_moments(X::Matrix, m, Σ; preserve_latin=false)\n\nTransforms X such that it get the specified mean and covariance.\n\nm, Σ   = [1,2], [2 1; 1 4] # Desired mean and covariance\nparticles = transform_moments(X, m, Σ)\njulia> cov(particles) ≈ Σ\ntrue\n\nNote, if X is a latin hypercube and Σ is non-diagonal, then the latin property is destroyed for all dimensions but the first. We provide a method preserve_latin=true) which absolutely preserves the latin property in all dimensions, but if you use this, the covariance of the sample will be slightly wrong\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.unsafe_comparisons","page":"API","title":"MonteCarloMeasurements.unsafe_comparisons","text":"unsafe_comparisons(onoff=true; verbose=true)\n\nToggle the use of a comparison function without warning. By default mean is used to reduce particles to a floating point number for comparisons. This function can be changed, example: set_comparison_function(median)\n\nunsafe_comparisons(mode=:reduction; verbose=true)\n\nOne can also specify a comparison mode, mode can take the values :safe, :montecarlo, :reduction. :safe is the same as calling unsafe_comparisons(false) and :reduction corresponds to true. If\n\n\n\n\n\n","category":"function"},{"location":"api/#MonteCarloMeasurements.wasserstein-Tuple{AbstractParticles,AbstractParticles,Any}","page":"API","title":"MonteCarloMeasurements.wasserstein","text":"wasserstein(p1::AbstractParticles,p2::AbstractParticles,p)\n\nReturns the Wasserstein distance of order p, to the pth power, between p1 and p2. I.e., for p=2, this returns W₂²\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.with_workspace-Tuple{Any,Any}","page":"API","title":"MonteCarloMeasurements.with_workspace","text":"with_workspace(f,P)\n\nIn some cases, defining a primitive function which particles are to be propagate through is not possible but allowing unsafe comparisons are not acceptable. One such case is functions that internally calculate eigenvalues of uncertain matrices. The eigenvalue calculation makes use of comparison operators. If the uncertainty is large, eigenvalues might change place in the sorted list of returned eigenvalues, completely ruining downstream computations. For this we recommend, in order of preference\n\nUse @bymap detailed in the documentation. Applicable if all uncertain values appears as arguments to your entry function.\nCreate a Workspace object and call it using your entry function. Applicable if uncertain parameters appear nested in an object that is an argument to your entry function:\n\n# desired computation: y = f(obj), obj contains uncertain parameters inside\ny = with_workspace(f, obj)\n# or equivalently\nw = Workspace(f, obj)\nuse_invokelatest = true # Set this to false to gain 0.1-1 ms, at the expense of world-age problems if w is created and used in the same function.\nw(obj, use_invokelatest)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.ℂ2ℂ_function-Union{Tuple{T}, Tuple{F}, Tuple{F,Complex{T}}} where T<:AbstractParticles where F<:Union{DataType, Function}","page":"API","title":"MonteCarloMeasurements.ℂ2ℂ_function","text":"ℂ2ℂ_function(f::Function, z::Complex{<:AbstractParticles})\n\napplies f : ℂ → ℂ to z::Complex{<:AbstractParticles}.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.ℝⁿ2ℂⁿ_function-Union{Tuple{N}, Tuple{T}, Tuple{F}, Tuple{F,AbstractArray{Particles{T,N},N1} where N1}} where N where T where F","page":"API","title":"MonteCarloMeasurements.ℝⁿ2ℂⁿ_function","text":"ℝⁿ2ℂⁿ_function(f::Function, p::AbstractArray{T})\n\nApplies  f : ℝⁿ → Cⁿ to an array of particles. E.g., LinearAlgebra.eigvals(p::Matrix{<:AbstractParticles}) = ℝⁿ2ℂⁿ_function(eigvals,p)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.ℝⁿ2ℂⁿ_function-Union{Tuple{N}, Tuple{T}, Tuple{F}, Tuple{F,AbstractArray{StaticParticles{T,N},N1} where N1}} where N where T where F","page":"API","title":"MonteCarloMeasurements.ℝⁿ2ℂⁿ_function","text":"ℝⁿ2ℂⁿ_function(f::Function, p::AbstractArray{T})\n\nApplies  f : ℝⁿ → Cⁿ to an array of particles. E.g., LinearAlgebra.eigvals(p::Matrix{<:AbstractParticles}) = ℝⁿ2ℂⁿ_function(eigvals,p)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.ℝⁿ2ℝⁿ_function-Union{Tuple{N}, Tuple{T}, Tuple{F}, Tuple{F,AbstractArray{Particles{T,N},N1} where N1}} where N where T where F","page":"API","title":"MonteCarloMeasurements.ℝⁿ2ℝⁿ_function","text":"ℝⁿ2ℝⁿ_function(f::Function, p::AbstractArray{T})\n\nApplies  f : ℝⁿ → ℝⁿ to an array of particles. E.g., Base.log(p::Matrix{<:AbstractParticles}) = ℝⁿ2ℝⁿ_function(log,p)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.ℝⁿ2ℝⁿ_function-Union{Tuple{N}, Tuple{T}, Tuple{F}, Tuple{F,AbstractArray{StaticParticles{T,N},N1} where N1}} where N where T where F","page":"API","title":"MonteCarloMeasurements.ℝⁿ2ℝⁿ_function","text":"ℝⁿ2ℝⁿ_function(f::Function, p::AbstractArray{T})\n\nApplies  f : ℝⁿ → ℝⁿ to an array of particles. E.g., Base.log(p::Matrix{<:AbstractParticles}) = ℝⁿ2ℝⁿ_function(log,p)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonteCarloMeasurements.@bymap-Tuple{Any}","page":"API","title":"MonteCarloMeasurements.@bymap","text":"@bymap f(p, args...)\n\nCall f with particles or vectors of particles by using map. This can be utilized if registering f using register_primitive fails. See also Workspace if bymap fails.\n\n\n\n\n\n","category":"macro"},{"location":"api/#MonteCarloMeasurements.@bypmap-Tuple{Any}","page":"API","title":"MonteCarloMeasurements.@bypmap","text":"@bypmap f(p, args...)\n\nCall f with particles or vectors of particles by using parallel pmap. This can be utilized if registering f using register_primitive fails. See also Workspace if bymap fails.\n\n\n\n\n\n","category":"macro"},{"location":"api/#MonteCarloMeasurements.@unsafe-Tuple{Any}","page":"API","title":"MonteCarloMeasurements.@unsafe","text":"@unsafe expression\n\nActivates unsafe comparisons for the provided expression only. The expression is surrounded by a try/catch block to robustly restore unsafe comparisons in case of exception.\n\n\n\n\n\n","category":"macro"},{"location":"api/#","page":"API","title":"API","text":"Base.:(≈)(p::AbstractParticles, a::AbstractParticles)\nMonteCarloMeasurements.:(≉)(a::AbstractParticles, b::AbstractParticles)","category":"page"},{"location":"api/#Base.:≈-Tuple{AbstractParticles,AbstractParticles}","page":"API","title":"Base.:≈","text":"p1 ≈ p2\n\nDetermine if two particles are not significantly different\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.:≉-Tuple{AbstractParticles,AbstractParticles}","page":"API","title":"Base.:≉","text":"p1 ≉ p2\n\nDetermine if two particles are significantly different\n\n\n\n\n\n","category":"method"},{"location":"examples/#Examples-1","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/#[Control-systems](https://github.com/baggepinnen/MonteCarloMeasurements.jl/blob/master/examples/controlsystems.jl)-1","page":"Examples","title":"Control systems","text":"","category":"section"},{"location":"examples/#","page":"Examples","title":"Examples","text":"This example shows how to simulate control systems (using ControlSystems.jl) with uncertain parameters. We calculate and display Bode diagrams, Nyquist diagrams and time-domain responses. We also illustrate how the package ControlSystemIdentification.jl interacts with MonteCarloMeasurements to facilitate the creation and analysis of uncertain systems.","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"We also perform some limited benchmarks.","category":"page"},{"location":"examples/#[Latin-Hypercube-Sampling](https://github.com/baggepinnen/MonteCarloMeasurements.jl/blob/master/examples/lhs.jl)-1","page":"Examples","title":"Latin Hypercube Sampling","text":"","category":"section"},{"location":"examples/#","page":"Examples","title":"Examples","text":"We show how to initialize particles with LHS and how to make sure the sample gets the desired moments. We also visualize the statistics of the sample.","category":"page"},{"location":"examples/#[How-MC-uncertainty-propagation-works](https://github.com/baggepinnen/MonteCarloMeasurements.jl/blob/master/examples/transformed_densities.jl)-1","page":"Examples","title":"How MC uncertainty propagation works","text":"","category":"section"},{"location":"examples/#","page":"Examples","title":"Examples","text":"We produce the first figure in this readme and explain in visual detail how different forms of uncertainty propagation propagates a probability distribution through a nonlinear function.","category":"page"},{"location":"examples/#[Robust-probabilistic-optimization](https://github.com/baggepinnen/MonteCarloMeasurements.jl/blob/master/examples/robust_controller_opt.jl)-1","page":"Examples","title":"Robust probabilistic optimization","text":"","category":"section"},{"location":"examples/#","page":"Examples","title":"Examples","text":"Here, we use MonteCarloMeasurements to perform robust optimization. With robust and probabilistic, we mean that we place some kind of bound on a quantile of an uncertain value, or otherwise make use of the probability distribution of some value that depend on the optimized parameters.","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"The application we consider is optimization of a PID controller. Normally, we are interested in controller performance and robustness against uncertainty. The robustness is often introduced by placing an upper bound on the, so called, sensitivity function. When the system to be controlled is parameterized by Particles, we can penalize both variance in the performance measure as well as the 90:th quantile of the maximum of the sensitivity function. This example illustrates how easy it is to incorporate probabilistic constrains or cost functions in an optimization problem using Particles.","category":"page"},{"location":"examples/#[Autodiff-and-Robust-optimization](https://github.com/baggepinnen/MonteCarloMeasurements.jl/blob/master/examples/autodiff_robust_opt.jl)-1","page":"Examples","title":"Autodiff and Robust optimization","text":"","category":"section"},{"location":"examples/#","page":"Examples","title":"Examples","text":"Another example using MonteCarloMeasurements to perform robust optimization, this time with automatic differentiation. We use Optim.jl to solve a linear program with probabilistic constraints using 4 different methods, two gradient free, one first-order and one second-order method. We demonstrate calculation of gradients of uncertain functions with uncertain inputs using both Zygote.jl and ForwardDiff.jl.","category":"page"},{"location":"examples/#Monte-Carlo-sampling-properties-1","page":"Examples","title":"Monte-Carlo sampling properties","text":"","category":"section"},{"location":"examples/#","page":"Examples","title":"Examples","text":"The variance introduced by Monte-Carlo sampling has some fortunate and some unfortunate properties. It decreases as 1/N, where N is the number of particles/samples. This unfortunately means that to get half the standard deviation in your estimate, you need to quadruple the number of particles. On the other hand, this variance does not depend on the dimension of the space, which is very fortunate.","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"In this package, we perform systematic sampling whenever possible. This approach exhibits lower variance than standard random sampling. Below, we investigate the variance of the mean estimator of a random sample from the normal distribution. The variance of the estimate of the mean is known to decrease as 1/N","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"default(l=(3,))\nN = 1000\nsvec = round.(Int, exp10.(LinRange(1, 3, 50)))\nvars = map(svec) do i\n  var(mean(randn(i)) for _ in 1:1000)\nend\nplot(svec, vars, yscale=:log10, xscale=:log10, lab=\"Random sampling\", xlabel=\"\\$N\\$\", ylabel=\"Variance\")\nplot!(svec, N->1/N, lab=\"\\$1/N\\$\", l=(:dash,))\nvars = map(svec) do i\n  var(mean(systematic_sample(i)) for _ in 1:1000)\nend\nplot!(svec, vars, lab=\"Systematic sampling\")\nplot!(svec, N->1/N^2, lab=\"\\$1/N^2\\$\", l=(:dash,))","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"(Image: variance plot)","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"As we can see, the variance of the standard random sampling decreases as expected. We also see that the variance for the systematic sample is considerably lower, and also scales as (almost) 1/N².","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"A simplified implementation of the systematic sampler is given below","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"function systematic_sample(N, d=Normal(0,1))\n    e   = rand()/N\n    y   = e:1/N:1\n    map(x->quantile(d,x), y)\nend","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"~~As we can see, a single random number is generated to seed the entire sample.~~ (This has been changed to e=0.5/N to have a correct mean.) The samples are then drawn deterministically from the quantile function of the distribution.","category":"page"},{"location":"examples/#Variational-inference-1","page":"Examples","title":"Variational inference","text":"","category":"section"},{"location":"examples/#","page":"Examples","title":"Examples","text":"See blog post by @cscherrer for an example of variational inference using Particles","category":"page"},{"location":"examples/#Differential-Equations-1","page":"Examples","title":"Differential Equations","text":"","category":"section"},{"location":"examples/#","page":"Examples","title":"Examples","text":"The tutorial for solving differential equations using Measurement works for Particles as well. A word of caution for actually using Measurements.jl in this example: while solving the pendulum on short time scales, linear uncertainty propagation works well, as evidenced by the below simulation of a pendulum with uncertain properties","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"function sim(±, tspan, plotfun=plot!; kwargs...)\n    g = 9.79 ± 0.02; # Gravitational constant\n    L = 1.00 ± 0.01; # Length of the pendulum\n    u₀ = [0 ± 0, π / 3 ± 0.02] # Initial speed and initial angle\n\n    #Define the problem\n    function simplependulum(du,u,p,t)\n        θ  = u[1]\n        dθ = u[2]\n        du[1] = dθ\n        du[2] = -(g/L) * sin(θ)\n    end\n\n    prob = ODEProblem(simplependulum, u₀, tspan)\n    sol = solve(prob, Tsit5(), reltol = 1e-6)\n\n    plotfun(sol.t, getindex.(sol.u, 2); kwargs...)\nend\n\ntspan = (0.0, 5)\nplot()\nsim(Measurements.:±, tspan, label = \"Linear\", xlims=(tspan[2]-5,tspan[2]))\nsim(MonteCarloMeasurements.:±, tspan, label = \"MonteCarlo\", xlims=(tspan[2]-5,tspan[2]))","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"(Image: window)","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"The mean and errorbars for both Measurements and MonteCarloMeasurements line up perfectly when integrating over 5 seconds.","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"However, the uncertainty in the pendulum coefficients implies that the frequency of the pendulum oscillation is uncertain, when solving on longer time scales, this should result in the phase being completely unknown, something linear uncertainty propagation does not handle","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"tspan = (0.0, 200)\nplot()\nsim(Measurements.:±, tspan, label = \"Linear\", xlims=(tspan[2]-5,tspan[2]))\nsim(MonteCarloMeasurements.:±, tspan, label = \"MonteCarlo\", xlims=(tspan[2]-5,tspan[2]))","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"(Image: window)","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"We now integrated over 200 seconds and look at the last 5 seconds. This result maybe looks a bit confusing, the linear uncertainty propagation is very sure about the amplitude at certain points but not at others, whereas the Monte-Carlo approach is completely unsure. Furthermore, the linear approach thinks that the amplitude at some points is actually much higher than the starting amplitude, implying that energy somehow has been added to the system! The picture might become a bit more clear by plotting the individual trajectories of the particles","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"plot()\nsim(Measurements.:±, tspan, label = \"Linear\", xlims=(tspan[2]-5,tspan[2]), l=(5,))\nsim(MonteCarloMeasurements.:∓, tspan, mcplot!, label = \"\", xlims=(tspan[2]-5,tspan[2]), l=(:black,0.1))","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"(Image: window)","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"It now becomes clear that each trajectory has a constant amplitude (although individual trajectories amplitudes vary slightly due to the uncertainty in the initial angle), but the phase is all mixed up due to the slightly different frequencies!","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"These problems grow with increasing uncertainty and increasing integration time. In fact, the uncertainty reported by Measurements.jl goes to infinity as the integration time does the same.","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"Of course, the added accuracy from using MonteCarloMeasurements does not come for free, as it costs some additional computation. We have the following timings for integrating the above system 100 seconds using three different uncertainty representations","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"Measurements.:±             14.596 ms  (729431 allocations: 32.43 MiB)   # Measurements.Measurement\nMonteCarloMeasurements.:∓   25.115 ms  (25788 allocations: 24.68 MiB)    # 100 StaticParticles\nMonteCarloMeasurements.:±   345.730 ms (696212 allocations: 838.50 MiB)  # 500 Particles","category":"page"},{"location":"examples/#MCMC-inference-using-Soss.jl-or-Turing.jl-1","page":"Examples","title":"MCMC inference using Soss.jl or Turing.jl","text":"","category":"section"},{"location":"examples/#","page":"Examples","title":"Examples","text":"The probabilistic programming language Soss.jl has native support for converting the inference result to Particles for further processing, see the Soss readme for further instruction.","category":"page"},{"location":"examples/#","page":"Examples","title":"Examples","text":"Turing.jl is another probabilistic programming language, and an interface between Turing and MonteCarloMeasurements is provided by Turing2MonteCarloMeasurements.jl with instructions and examples in the readme.","category":"page"},{"location":"overloading/#Supporting-new-functions-1","page":"Supporting new functions","title":"Supporting new functions","text":"","category":"section"},{"location":"overloading/#Overloading-a-new-function-1","page":"Supporting new functions","title":"Overloading a new function","text":"","category":"section"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"If a method for Particles is not implemented for your function yourfunc, the pattern to register your function looks like this","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"register_primitive(yourfunc)","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"This defines both a one-argument method and a multi-arg method for both Particles and StaticParticles. If you only want to define one of these, see register_primitive_single/register_primitive_multi. If the function is from base or stdlib, you can just add it to the appropriate list in the source and submit a PR :)","category":"page"},{"location":"overloading/#Monte-Carlo-simulation-by-map/pmap-1","page":"Supporting new functions","title":"Monte-Carlo simulation by map/pmap","text":"","category":"section"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"Some functions will not work when the input arguments are of type Particles. For this kind of function, we provide a fallback onto a traditional map(f,p.particles). The only thing you need to do is to decorate the function call with the function bymap or the macro @bymap like so:","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"f(x) = 3x^2\np = 1 ± 0.1\nr = @bymap f(p) # bymap(f,p) may give better error traces","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"We further provide the macro @bypmap (and bypmap) which does exactly the same thing, but with a pmap (parallel map) instead, allowing you to run several invocations of f in a distributed fashion.","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"These utilities will map the function f over each element of p::Particles{T,N}, such that f is only called with arguments of type T, e.g., Float64. This handles arguments that are multivaiate particles <: Vector{<:AbstractParticles} as well.","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"These utilities will typically be slower than calling f(p). If f is very expensive, @bypmap might prove prove faster than calling f with p, it's worth a try. The usual caveats for distributed computing applies, all code must be loaded on all workers etc.","category":"page"},{"location":"overloading/#Array-to-array-functions-1","page":"Supporting new functions","title":"Array-to-array functions","text":"","category":"section"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"These functions might not work with Particles out of the box. Special cases are currently implemented for","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"exp : ℝ(n×n) → ℝ(n×n)   matrix exponential\nlog : ℝ(n×n) → C(n×n)   matrix logarithm\neigvals : ℝ(n×n) → C(n) warning: eigenvalues are sorted, when two eigenvalues cross, this function is nondifferentiable. Eigenvalues can thus appear to have dramatically widened distributions. Make sure you interpret the result of this call in the right way.","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"The function  ℝⁿ2ℝⁿ_function(f::Function, p::AbstractArray{T}) applies f : ℝⁿ → ℝⁿ to an array of particles. See also ℝⁿ2ℂⁿ_function which is used to implement, e.g., log,eigvals","category":"page"},{"location":"overloading/#Complex-functions-1","page":"Supporting new functions","title":"Complex functions","text":"","category":"section"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"These functions do not work with Particles out of the box. Special cases are currently implemented for","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"sqrt, exp, sin, cos","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"We also provide in-place versions of the above functions, e.g.,","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"sqrt!(out, p), exp!(out, p), sin!(out, p), cos!(out, p)","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"The function ℂ2ℂ_function(f::Function, z) (ℂ2ℂ_function!(f::Function, out, z)) applies f : ℂ → ℂ to z::Complex{<:AbstractParticles}.","category":"page"},{"location":"overloading/#Difficult-cases-1","page":"Supporting new functions","title":"Difficult cases","text":"","category":"section"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"Sometimes, defining a primitive function can be difficult, such as when the uncertain parameters are baked into some object. In such cases, we can call the function unsafe_comparisons(true), which defines all comparison operators for uncertain values to compare using the mean. Note however that this enabling this is somewhat unsafe as this corresponds to a fallback to linear uncertainty propagation, why it's turned off by default. We also provide the macro @unsafe ex to enable mean comparisons only locally in the expression ex.","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"In some cases, defining a primitive is not possible but allowing unsafe comparisons are not acceptable. One such case is functions that internally calculate eigenvalues of uncertain matrices. The eigenvalue calculation makes use of comparison operators. If the uncertainty is large, eigenvalues might change place in the sorted list of returned eigenvalues, completely ruining downstream computations. For this we recommend, in order of preference","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"Use bymap. Applicable if all uncertain values appears as arguments to your entry function.\nCreate a Workspace object and call it using your entry function. Applicable if uncertain parameters appear nested in an object that is an argument to your entry function:","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"# desired computation: y = f(obj), obj contains uncertain parameters inside\ny = with_workspace(f, obj)\n# or equivalently\nw = Workspace(f,obj) # This is somewhat expensive and can be reused\nuse_invokelatest = true # Set this to false to gain 0.1-1 ms, at the expense of world-age problems if w is created and used in the same function.\nw(obj, use_invokelatest)","category":"page"},{"location":"overloading/#","page":"Supporting new functions","title":"Supporting new functions","text":"This interface is so far not tested very well and may throw strange errors. Some care has been taken to make error messages informative. Internally, a w::Workspace object is created that tries to automatically construct an object identical to obj, but where all uncertain parameters are replaced by conventional Real. If the heuristics used fail, an error message is displayed detailing which method you need to implement to make it work. When called, w populates the internal buffer object with particle i, calls f using a Particles-free obj and stores the result in an output object at particle index  i. This is done for i ∈ 1:N after which the output is returned. Some caveats include: Workspace must not be created or used inside a @generated function.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(Image: logo) (Image: Build Status) (Image: codecov) (Image: )","category":"page"},{"location":"#MonteCarloMeasurements-1","page":"Home","title":"MonteCarloMeasurements","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"This package facilitates working with probability distributions by means of Monte-Carlo methods, in a way that allows for propagation of probability distributions through functions. This is useful for, e.g.,  nonlinear uncertainty propagation. A variable or parameter might be associated with uncertainty if it is measured or otherwise estimated from data. We provide two core types to represent probability distributions: Particles and StaticParticles, both <: Real. (The name \"Particles\" comes from the particle-filtering literature.) These types all form a Monte-Carlo approximation of the distribution of a floating point number, i.e., the distribution is represented by samples/particles. Correlated quantities are handled as well, see multivariate particles below.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Although several interesting use cases for doing calculations with probability distributions have popped up (see Examples), the original goal of the package is similar to that of Measurements.jl, to propagate the uncertainty from input of a function to the output. The difference compared to a Measurement is that Particles represent the distribution using a vector of unweighted particles, and can thus represent arbitrary distributions and handle nonlinear uncertainty propagation well. Functions like f(x) = x², f(x) = sign(x) at x=0 and long-time integration, are examples that are not handled well using linear uncertainty propagation ala Measurements.jl. MonteCarloMeasurements also support correlations between quantities.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"A number of type Particles behaves just as any other Number while partaking in calculations. Particles also behave like a distribution, so after a calculation, an approximation to the complete distribution of the output is captured and represented by the output particles. mean, std etc. can be extracted from the particles using the corresponding functions. Particles also interact with Distributions.jl, so that you can call, e.g., Normal(p) and get back a Normal type from distributions or fit(Gamma, p) to get a Gammadistribution. Particles can also be iterated, asked for maximum/minimum, quantile etc. If particles are plotted with plot(p), a histogram is displayed. This requires Plots.jl. A kernel-density estimate can be obtained by density(p) is StatsPlots.jl is loaded. A Measurements.Measurements can be converted to particles by calling the Particles constructor.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Below, we show an example where an input uncertainty is propagated through σ(x)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(Image: transformed densities)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"In the figure above, we see the probability-density function of the input p(x) depicted on the x-axis. The density of the output p(y) = f(x) is shown on the y-axis. Linear uncertainty propagation does this by linearizing f(x) and using the equations for an affine transformation of a Gaussian distribution, and hence produces a Gaussian approximation to the output density. The particles form a sampled approximation of the input density p(x). After propagating them through f(x), they form a sampled approximation to p(y) which correspond very well to the true output density, even though only 20 particles were used in this example. The figure can be reproduced by examples/transformed_densities.jl.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"For a comparison of uncertainty propagation and nonlinear filtering, see notes below.","category":"page"},{"location":"#Basic-Examples-1","page":"Home","title":"Basic Examples","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"using MonteCarloMeasurements, Distributions\n\njulia> 1 ± 0.1\nPart10000(1.0 ± 0.1)\n\njulia> p = StaticParticles(100)\nSPart100(0.0 ± 0.999)\n\njulia> std(p)\n0.9986403042113867\n\njulia> var(p)\n0.997282457195411\n\njulia> mean(p)\n-4.6074255521943994e-17\n\njulia> f = x -> 2x + 10\n#95 (generic function with 1 method)\n\njulia> f(p) ≈ 10 # ≈ determines if f(p) is within 2σ of 10\ntrue\n\njulia> f(p) ≲ 15 # ≲ (\\lesssim) tests if f(p) is significantly less than 15\ntrue\n\njulia> Normal(f(p)) # Fits a normal distribution\nNormal{Float64}(μ=9.9872274542161, σ=2.1375718437608633)\n\njulia> fit(Normal, f(p)) # Same as above\nNormal{Float64}(μ=9.9872274542161, σ=2.1268571304548938)\n\njulia> Particles(100, Uniform(0,2)) # A distribution can be supplied\nPart100(1.0 ± 0.58)\n\njulia> Particles(1000, MvNormal([0,0],[2. 1; 1 4])) # A multivariate distribution will cause a vector of correlated particles\n2-element Array{Particles{Float64,1000},1}:\n 0.0254 ± 1.4\n 0.0641 ± 2.0","category":"page"},{"location":"#Why-a-package-1","page":"Home","title":"Why a package","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Convenience. Also, the benefit of using this number type instead of manually calling a function f with perturbed inputs is that, at least in theory, each intermediate operation on Particles can exploit SIMD, since it's performed over a vector. If the function f is called several times, however, the compiler might not be smart enough to SIMD the entire thing. Further, any dynamic dispatch is only paid for once, whereas it would be paid for N times if doing things manually. The same goes for calculations that are done on regular input arguments without uncertainty, these will only be done once for Particles whereas they will be done N times if you repeatedly call f. One could perhaps also make an argument for cache locality being favorable for the Particles type, but I'm not sure this holds for all examples. Below, we show a small benchmark example (additional Benchmark) where we calculate a QR factorization of a matrix using Particles and compare it to manually doing it many times","category":"page"},{"location":"#","page":"Home","title":"Home","text":"using BenchmarkTools\nA = [Particles(1000) for i = 1:3, j = 1:3]\nB = similar(A, Float64)\n@btime qr($A)\n  119.243 μs (257 allocations: 456.58 KiB)\n@btime foreach(_->qr($B), 1:1000) # Manually do qr 1000 times\n  3.916 ms (4000 allocations: 500.00 KiB)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"that's about a 30-fold reduction in time, and the repeated qr didn't even bother to sample new input points or store and handle the statistics of the result. The type StaticParticles contains a statically sized, stack-allocated vector from StaticArrays.jl. This type is suitable if the number of particles is small, say < 500 ish (but expect long compilation times if > 100, especially on julia < v1.1).","category":"page"},{"location":"#","page":"Home","title":"Home","text":"A = [StaticParticles(100) for i = 1:3, j = 1:3]\nB = similar(A, Float64)\n@btime qr($(copy(A)))\n  8.392 μs (16 allocations: 18.94 KiB)\n@btime map(_->qr($B), 1:100);\n  690.590 μs (403 allocations: 50.92 KiB)\n# Wow that's over 80 times faster\n# Bigger matrix\nA = [StaticParticles(100) for i = 1:30, j = 1:30]\nB = similar(A, Float64)\n@btime qr($(copy(A)))\n  1.823 ms (99 allocations: 802.63 KiB)\n@btime map(_->qr($B), 1:100);\n  75.068 ms (403 allocations: 2.11 MiB)\n# 40 times faster","category":"page"},{"location":"#","page":"Home","title":"Home","text":"StaticParticles allocate much less memory than regular Particles, but are more stressful for the compiler to handle.","category":"page"},{"location":"#Constructors-1","page":"Home","title":"Constructors","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The most basic constructor of Particles acts more or less like randn(N), i.e., it creates a particle cloud with distribution Normal(0,1). To create a particle cloud with distribution Normal(μ,σ), you can call μ + σ*Particles(N), or Particles(N, Normal(μ,σ)). This last constructor works with any distribution from which one can sample. One can also call (Particles/StaticParticles)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Particles(v::Vector) pre-sampled particles\nParticles(N = 10000, d::Distribution = Normal(0,1)) samples N particles from the distribution d.\nThe ± operator (\\pm) (similar to Measurements.jl). We have μ ± σ = μ + σ*Particles(DEFAULT_NUM_PARTICLES), where the global constant DEFAULT_NUM_PARTICLES = 10000. You can change this if you would like, or simply define your own ± operator like ±(μ,σ) = μ + σ*Particles(my_default_number, my_default_distribution). The upside-down operator ∓ (\\mp) instead creates a StaticParticles(100).\nThe .. binary infix operator creates uniformly sampled particles, e.g., 2..3 = Particles(Uniform(2,3))","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Common univariate distributions are sampled systematically, meaning that a single random number is drawn and used to seed the sample. This will reduce the variance of the sample. If this is not desired, call Particles(N, [d]; systematic=false) The systematic sample can maintain its originally sorted order by calling Particles(N, permute=false), but the default is to permute the sample so as to not have different Particles correlate strongly with each other.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Construction of Particles as sigma points or by latin hypercube sampling is detailed below.","category":"page"},{"location":"#Multivariate-particles-1","page":"Home","title":"Multivariate particles","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The constructors can be called with multivariate distributions, returning v::Vector{Particle} where particles are sampled from the desired multivariate distribution. Once v is propagated through a function v2 = f(v), the results can be analyzed by, e.g., asking for mean(v2) and cov(v2), or by fitting a multivariate distribution, e.g., MvNormal(v2).","category":"page"},{"location":"#","page":"Home","title":"Home","text":"A v::Vector{Particle} can be converted into a Matrix by calling Matrix(v) and this will have a size of N × dim. ~~You can also index into v like it was already a matrix.~~(This was a bad idea)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Broadcasting the ±/∓ operators works as you would expect, zeros(3) .± 1 gives you a three-vector of independent particles, so does zeros(3) .+ Particles.(N).","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Independent multivariate systematic samples can be created using the function outer_product or the non-exported operator ⊗ (\\otimes).","category":"page"},{"location":"#Examples-1","page":"Home","title":"Examples","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The following example creates a vector of two Particles. Since they were created independently of each other, they are independent and uncorrelated and have the covariance matrix Σ = Diagonal([1², 2²]). The linear transform with the matrix A should in theory change this covariance matrix to AΣAᵀ, which we can verify be asking for the covariance matrix of the output particles.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"julia> p = [1 ± 1, 5 ± 2]\n2-element Array{Particles{Float64,10000},1}:\n 1.0 ± 1.0\n 5.0 ± 2.0\n\njulia> A = randn(2,2)\n2×2 Array{Float64,2}:\n -1.80898  -1.24566\n  1.41308   0.196504\n\njulia> y = A*p\n2-element Array{Particles{Float64,10000},1}:\n -8.04 ± 3.1\n  2.4 ± 1.5\n\njulia> cov(y)\n2×2 Array{Float64,2}:\n  9.61166  -3.59812\n -3.59812   2.16701\n\njulia> A*Diagonal([1^2, 2^2])*A'\n2×2 Array{Float64,2}:\n  9.4791   -3.53535\n -3.53535   2.15126","category":"page"},{"location":"#","page":"Home","title":"Home","text":"To create particles that exhibit a known covariance/correlation, use the appropriate constructor, e.g.,","category":"page"},{"location":"#","page":"Home","title":"Home","text":"julia> p = Particles(10000, MvLogNormal(MvNormal([2, 1],[2. 1;1 3])))\n2-element Array{Particles{Float64,10000},1}:\n 19.3 ± 48.0\n 11.9 ± 43.0\n\njulia> cov(log.(p))\n2×2 Array{Float64,2}:\n 1.96672  1.0016\n 1.0016   2.98605\n\njulia> mean(log.(p))\n2-element Array{Float64,1}:\n 1.985378409751101\n 1.000702538699887","category":"page"},{"location":"#Sigma-points-1","page":"Home","title":"Sigma points","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The unscented transform uses a small number of points called sigma points to propagate the first and second moments of a probability density. We provide a function sigmapoints(μ, Σ) that creates a Matrix of 2n+1 sigma points, where n is the dimension. This can be used to initialize any kind of AbstractParticles, e.g.:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"julia> m = [1,2]\n\njulia> Σ = [3. 1; 1 4]\n\njulia> p = StaticParticles(sigmapoints(m,Σ))\n2-element Array{StaticParticles{Float64,5},1}:\n 1.0 ± 1.7 # 2n+1 = 5 particles\n 2.0 ± 2.0\n\njulia> cov(p) ≈ Σ\ntrue\n\njulia> mean(p) ≈ m\ntrue","category":"page"},{"location":"#","page":"Home","title":"Home","text":"sigmapoints also accepts a Normal/MvNormal object as input.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"danger: Caveat\nIf you are creating several one-dimensional uncertain values using sigmapoints independently, they will be strongly correlated. Use the multidimensional constructor! Example:p = StaticParticles(sigmapoints(1, 0.1^2))               # Wrong!\nζ = StaticParticles(sigmapoints(0.3, 0.1^2))             # Wrong!\nω = StaticParticles(sigmapoints(1, 0.1^2))               # Wrong!\n\np,ζ,ω = StaticParticles(sigmapoints([1, 0.3, 1], 0.1^2)) # Correct","category":"page"},{"location":"#Latin-hypercube-sampling-1","page":"Home","title":"Latin hypercube sampling","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"We do not provide functionality for latin hypercube sampling, rather, we show how to use the package LatinHypercubeSampling.jl to initialize particles.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"# import Pkg; Pkg.add(\"LatinHypercubeSampling\")\nusing MonteCarloMeasurements, LatinHypercubeSampling\nndims  = 2\nN      = 100  # Number of particles\nngen   = 2000 # How long to run optimization\nX, fit = LHCoptim(N,ndims,ngen)\nm, Σ   = [1,2], [2 1; 1 4] # Desired mean and covariance\nparticle_matrix = transform_moments(X,m,Σ)\np      = Particles(particle_matrix) # These are our LHS particles with correct moments\nplot(scatter(eachcol(particles)..., title=\"Sample\"), plot(fit, title=\"Fitness vs. iteration\"))\n\njulia> mean(p)\n2-element Array{Float64,1}:\n 1.0\n 2.0\n\njulia> cov(p)\n2×2 Array{Float64,2}:\n 2.0  1.0\n 1.0  4.0","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Latin hypercube sampling creates an approximately uniform sample in ndims dimensions. The applied transformation gives the particles the desired mean and covariance. Caveat: Unfortunately, endowing the sampled latin hypercube with a desired non-diagonal covariance matrix destroys the latin properties for all dimensions but the first. This is less of a problem for diagonal covariance matrices provided that the latin optimizer was run sufficiently long.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The statistics of the sample can be visualized:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"using StatsPlots\ncorrplot(particles)\nplot(density(p[1]), density(p[2]))","category":"page"},{"location":"#","page":"Home","title":"Home","text":"see also examples/lhs.jl.","category":"page"},{"location":"#Plotting-1","page":"Home","title":"Plotting","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"An instance of p::Particles can be plotted using plot(p), that creates a histogram by default. If StatsPlots.jl is available, one can call density(p) to get a slightly different visualization. Vectors of particles can be plotted using one of","category":"page"},{"location":"#","page":"Home","title":"Home","text":"errorbarplot(x,y,[q=0.025]): q determines the quantiles, set to 0 for max/min. You can also specify both bounds, e.g., q = (0.01, 0.99).\nmcplot(x,y): Plots all trajectories\nribbonplot(x,y,[q=0.025]): Plots with shaded area from quantile q to 1-q. You can also specify both bounds, e.g., q = (0.01, 0.99).\nPlot recipes from StatsPlots.jl that do not work with Particles or vectors of Particles can often be made to work by converting the particles to an array, e.g., violin(Array([1±0.5, 4±1, 2±0.1])).","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Below is an example using ControlSystems.jl","category":"page"},{"location":"#","page":"Home","title":"Home","text":"using ControlSystems, MonteCarloMeasurements, StatsPlots\n\np = 1 ± 0.1\nζ = 0.3 ± 0.1\nω = 1 ± 0.1\nG = tf([p*ω], [1, 2ζ*ω, ω^2]) # Transfer function with uncertain parameters\n\ndc = dcgain(G)[]\n# Part500(1.01 ± 0.147)\ndensity(dc, title=\"Probability density of DC-gain\")","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(Image: A density)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"w = exp10.(LinRange(-1,1,200)) # Frequency vector\nmag, phase = bode(G,w) .|> vec\n\nerrorbarplot(w,mag, yscale=:log10, xscale=:log10)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(Image: A bodeplot with errorbars)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"mcplot(w,mag, yscale=:log10, xscale=:log10, alpha=0.2)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(Image: A bodeplot with lots of lines)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"ribbonplot(w,mag, yscale=:log10, xscale=:log10, alpha=0.2)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(Image: A bodeplot with a ribbon)","category":"page"},{"location":"#Limitations-1","page":"Home","title":"Limitations","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"One major limitation is functions that contain control flow, where the branch is decided by an uncertain value. Consider the following case","category":"page"},{"location":"#","page":"Home","title":"Home","text":"function negsquare(x)\n    x > 0 ? x^2 : -x^2\nend\np = 0 ± 1","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Ideally, half of the particles should turn out negative and half positive when applying negsquare(p). However, this will not happen as the x > 0 is not defined for uncertain values. To circumvent this, define negsquare as a primitive using register_primitive described in Overloading a new function. Particles will then be propagated one by one through the entire function negsquare. Common such functions from Base, such as max/min etc. are already registered.","category":"page"},{"location":"#Comparison-mode-1","page":"Home","title":"Comparison mode","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Some functions perform checks like if error < tol. If error isa Particles, this will use a very conservative check by default by checking that all particles ∈ error fulfill the check. There are a few different options available for how to compare two uncertain quantities, chosen by specifying a comparison mode. The modes are chosen by unsafe_comparisons(mode) and the options are","category":"page"},{"location":"#","page":"Home","title":"Home","text":":safe: the default described above, throws an error if uncertain values share support.\n:montecarlo: slightly less conservative than :safe, checks if either all pairwise particles fulfill the comparison, or all pairwise particles fail the comparison. If some pairs pass and some fail, an error is thrown.\n:reduction: Reduce uncertain values to a single number, e.g. by calling mean (default) before performing the comparison, never throws an error.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"To sum up, if two uncertain values are compared, and they have no mutual support, then all comparison modes are equal. If they share support, :safe will error and :montecarlo will work if the all pairwise particles either pass or fail the comparison. :reduction will always work, but is maximally unsafe in the sense that it might not perform a meaningful check for your application.","category":"page"},{"location":"#Calculating-probability-1","page":"Home","title":"Calculating probability","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"If you would like to calculate the empirical probability that a value represented by Particles fulfils a condition, you may use the macro @prob:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"julia> p = Particles()\nPart10000(0.0 ± 1.0)\n\njulia> @prob p < 1\n0.8413\n\njulia> mean(p.particles .< 1)\n0.8413","category":"page"},{"location":"#When-to-use-what?-1","page":"Home","title":"When to use what?","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Situation Action\nLinear functions Use linear uncertainty propagation, i.e., Measurements.jl\nHighly nonlinear/discountinuous functions Use MonteCarloMeasurements\nCorrelated quantities Use MonteCarloMeasurements\nLarge uncertainties in input Use MonteCarloMeasurements\nSmall uncertainties in input in relation to the curvature of the function Use Measurements\nInterested in low probability events / extremas Use MonteCarloMeasurements / IntervalArithmetic.jl\nLimited computational budget Use Measurements or StaticParticles with sigmapoints. See benchmark below.\nNon-Gaussian input distribution Use MonteCarloMeasurements\nCalculate tail integrals accurately This requires some form of importance sampling, not yet fully supported","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Due to Jensen's inequality, linear uncertainty propagation will always underestimate the mean of nonlinear convex functions and overestimate the mean of concave functions. From wikipedia","category":"page"},{"location":"#","page":"Home","title":"Home","text":"In its simplest form the inequality states that the convex transformation of a mean is less than or equal to the mean applied after convex transformation; it is a simple corollary that the opposite is true of concave transformations.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Linear uncertainty propagation does thus not allow you to upperbound/lowerbound the output uncertainty of a convex/concave function, and will be conservative in the reverse case.","category":"page"},{"location":"#Benchmark-1","page":"Home","title":"Benchmark","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The benchmark results below comes from examples/controlsystems.jl The benchmark consists of calculating the Bode curves for a linear system with uncertain parameters","category":"page"},{"location":"#","page":"Home","title":"Home","text":"w  = exp10.(LinRange(-1,1,200)) # Frequency vector\np  = 1 ± 0.1\nζ  = 0.3 ± 0.1\nω  = 1 ± 0.1\nG  = tf([p*ω], [1, 2ζ*ω, ω^2])\nt1 = @belapsed bode($G,$w)\n   ⋮","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Benchmark Result\nTime with 500 particles 1.3632ms\nTime with regular floating point 0.0821ms\nTime with Measurements 0.1132ms\nTime with 100 static part. 0.2375ms\nTime with static sigmapoints. 0.0991ms\n500×floating point time 41.0530ms\nSpeedup factor vs. Manual 30.1x\nSlowdown factor vs. Measurements 12.0x\nSlowdown static vs. Measurements 2.1x\nSlowdown sigma vs. Measurements 0.9x","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The benchmarks show that using Particles is much faster than doing the Monte-Carlo sampling manually. We also see that we're about 12 times slower than linear uncertainty propagation with Measurements.jl if we are using standard Particles, StaticParticles are within a factor of 2 of Measurements and StaticParticles with sigmapoints are actually 10% faster than Measurements (this is because 7 sigmapoints fit well into two of the processors SIMD registers, making the extra calculations very cheap).","category":"page"},{"location":"#Comparison-to-nonlinear-filtering-1","page":"Home","title":"Comparison to nonlinear filtering","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The table below compares methods for uncertainty propagation with their parallel in nonlinear filtering.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Uncertainty propagation Dynamic filtering Method\nMeasurements.jl Extended Kalman filter Linearization\nParticles(sigmapoints) Unscented Kalman Filter Unscented transform\nParticles Particle Filter Monte Carlo (sampling)","category":"page"},{"location":"#Faster-exp,log-1","page":"Home","title":"Faster exp,log","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"If the user manually loads the library SLEEFPirates.jl, some functions are overloaded for Particles of Float64,Float32 eltypes making these functions 2-16 times faster depending on the processor SIMD width.","category":"page"},{"location":"#Citing-1","page":"Home","title":"Citing","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"See CITATION.bib   ArXiv article MonteCarloMeasurements.jl: Nonlinear Propagation of Arbitrary Multivariate Distributions by means of Method Overloading","category":"page"}]
}
